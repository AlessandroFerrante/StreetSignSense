{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO03xMDtRMIN"
   },
   "source": [
    "# YOLO12 Model Analysis (n,s,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi \n",
    "!pip install ultralytics -q\n",
    "!pip install numpy==1.26.0\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\", \"invalid value encountered in less\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"invalid value encountered in greater\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHx34D_rRYtD"
   },
   "source": [
    "## Validation YOLO12n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEisoFeSRbN2"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "modelN = YOLO(\"/kaggle/input/streetsignsensey12n/pytorch/streetsignsensey12n_361e_final/1/streetsignsense/yolo12n_run/weights/best.pt\")\n",
    "resultN = modelN.val(data=\"/kaggle/input/streetsignsensey12n/pytorch/streetsignsensey12n_361e_final/1/data.yaml\", device='0,1')\n",
    "print(\"\\n\\nmAP50-95:\",resultN.box.map)  # map50-95\n",
    "print(\"mAP-50:\",resultN.box.map50)  # map50\n",
    "print(\"mAP-75:\",resultN.box.map75)  # map75\n",
    "print(\"Average Precision: \", np.mean(resultN.box.p))  # precision\n",
    "print(\"Average Recall: \",np.mean(resultN.box.r))  # recall\n",
    "print(\"Average F1: \",np.mean(resultN.box.f1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXnodzBg_e45"
   },
   "source": [
    "## Validation YOLO12s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acwRZFhi_e47"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "modelS = YOLO(\"/kaggle/input/streetsignsensey12s/pytorch/streetsignsensey12s_270e_final/1/streetsignsense/yolo12s_run/weights/best.pt\")\n",
    "resultS = modelS.val(data=\"/kaggle/input/streetsignsensey12s/pytorch/streetsignsensey12s_270e_final/1/data.yaml\", device='0,1')\n",
    "print(\"\\n\\nmAP50-95:\",resultS.box.map)  # map50-95\n",
    "print(\"mAP-50:\",resultS.box.map50)  # map50\n",
    "print(\"mAP-75:\",resultS.box.map75)  # map75\n",
    "print(\"Average Precision: \", np.mean(resultS.box.p))  # precision\n",
    "print(\"Average Recall: \",np.mean(resultS.box.r))  # recall\n",
    "print(\"Average F1: \",np.mean(resultS.box.f1)) #f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX4ozpMK_fNW"
   },
   "source": [
    "## Validation YOLO12m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYTRJ_7Y_fNX"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "modelM = YOLO(\"/kaggle/input/streetsignsensey12m/pytorch/streetsignsensey12m_263e/1/streetsignsense/yolo12m_run/weights/best.pt\")\n",
    "resultM = modelM.val(data=\"/kaggle/input/streetsignsensey12m/pytorch/streetsignsensey12m_263e/1/data.yaml\", device='0,1')\n",
    "print(\"\\n\\nmAP50-95:\",resultM.box.map)  # map50-95\n",
    "print(\"mAP-50:\",resultM.box.map50)  # map50\n",
    "print(\"mAP-75:\",resultM.box.map75)  # map75\n",
    "print(\"Average Precision: \", np.mean(resultM.box.p))  # precision\n",
    "print(\"Average Recall: \",np.mean(resultM.box.r))  # recall\n",
    "print(\"Average F1: \",np.mean(resultM.box.f1)) #f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhRK821QBop5"
   },
   "source": [
    "## Comparison of mAP between different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5tw2C98BnJm",
    "outputId": "fb380b5a-1733-4f9e-89d2-34d9b4b80029"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['mAP-50-95', 'mAP-50', 'mAP-75']\n",
    "models = ['Yolo12n', 'Yolo12s', 'Yolo12m']\n",
    "values = np.array([\n",
    "    [resultN.box.map, resultS.box.map, resultM.box.map],        # values for mAP-50-95\n",
    "    [resultN.box.map50, resultS.box.map50, resultM.box.map50],  # values for mAP-50\n",
    "    [resultN.box.map75, resultS.box.map75, resultM.box.map75]   # values for mAP-75\n",
    "])\n",
    "num_metrics = len(metrics)\n",
    "num_models = len(models)\n",
    "\n",
    "column_width = 0.2\n",
    "gap = 0.1\n",
    "position_bar = np.arange(num_metrics) * (num_models * column_width + gap)\n",
    "\n",
    "colors = ['#F50C00', '#00FF66', '#007BFF']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i in range(num_models):\n",
    "    bars = ax.bar(position_bar + i * column_width, values[:, i], column_width, label=models[i], color=colors[i])\n",
    "    ax.bar_label(bars, fmt='%.3f', padding=3, fontsize=9)\n",
    "\n",
    "ax.set_xlabel('metrics')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Comparison of mAP between different models')\n",
    "ax.set_xticks(position_bar + (num_models - 1) * column_width / 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Models')\n",
    "ax.set_ylim(0, np.max(values) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3fA0bohDuIw"
   },
   "source": [
    "## Comparsion Training Loss and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSxI20LhD2ps",
    "outputId": "d4fd2c9b-e173-4687-c363-3ba4ecfa75a6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_csv_n = '/kaggle/input/streetsignsensey12n/pytorch/streetsignsensey12n_361e_final/1/streetsignsense/yolo12n_run/results.csv' # modello N\n",
    "path_csv_s = '/kaggle/input/streetsignsensey12s/pytorch/streetsignsensey12s_270e_final/1/streetsignsense/yolo12s_run/results.csv' # modello S\n",
    "path_csv_m = '/kaggle/input/streetsignsensey12m/pytorch/streetsignsensey12m_263e/1/streetsignsense/yolo12m_run/results.csv' # modello M\n",
    "\n",
    "paths = [path_csv_n, path_csv_s, path_csv_m]\n",
    "modelli = ['Yolo12n', 'Yolo12s', 'Yolo12m']\n",
    "\n",
    "colors_val = ['#87CEFA', '#1E90FF', '#0000CD']\n",
    "colors_train = ['#FFA07A', '#FF8C00', '#FF4500']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "all_data_found = True\n",
    "for i, path in enumerate(paths):\n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        data.columns = data.columns.str.strip()\n",
    "\n",
    "        # YOLO salva più loss (box, cls, dfl).\n",
    "        # Usiamo 'val/box_loss' e 'train/box_loss' come metriche di confronto.\n",
    "\n",
    "        epoch = data['epoch']\n",
    "        val_loss = data['val/box_loss']     # Puoi cambiarla con 'val/cls_loss'\n",
    "        train_loss = data['train/box_loss'] # Puoi cambiarla con 'train/cls_loss'\n",
    "\n",
    "        # Validation Loss (Blu)\n",
    "        ax.plot(epoch, val_loss, label=f'Validation Loss {modelli[i]}', color=colors_val[i], linewidth=2, linestyle='-')\n",
    "        # Training Loss (Arancione)\n",
    "        ax.plot(epoch, train_loss, label=f'Training Loss {modelli[i]}', color=colors_train[i], linewidth=2, linestyle='-')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"File non trovato: '{path}'\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "    except KeyError as e:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"Errore nel file: {path}. Colonna non trovata: {e}\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "\n",
    "ax.set_xlabel('Epoche')\n",
    "ax.set_ylabel('Box Loss (Train & Val)')\n",
    "ax.set_title('Comparison of Training and Validation box Loss between YOLO12 Models')\n",
    "ax.legend(title=' YOLO12 Models (n, m, s)')\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "if all_data_found:\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "all_data_found = True\n",
    "for i, path in enumerate(paths):\n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        data.columns = data.columns.str.strip()\n",
    "\n",
    "        # YOLO salva più loss (box, cls, dfl).\n",
    "        # Usiamo 'val/box_loss' e 'train/box_loss' come metriche di confronto.\n",
    "\n",
    "        epoch = data['epoch']\n",
    "        val_loss = data['val/cls_loss']     # Puoi cambiarla con 'val/cls_loss'\n",
    "        train_loss = data['train/cls_loss'] # Puoi cambiarla con 'train/cls_loss'\n",
    "\n",
    "        # Validation Loss (Blu)\n",
    "        ax.plot(epoch, val_loss, label=f'Validation Loss {modelli[i]}', color=colors_val[i], linewidth=2, linestyle='-')\n",
    "        # Training Loss (Arancione)\n",
    "        ax.plot(epoch, train_loss, label=f'Training Loss {modelli[i]}', color=colors_train[i], linewidth=2, linestyle='-')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"File non trovato: '{path}'\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "    except KeyError as e:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"Errore nel file: {path}. Colonna non trovata: {e}\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "\n",
    "ax.set_xlabel('Epoche')\n",
    "ax.set_ylabel('Box Loss (Train & Val)')\n",
    "ax.set_title('Comparison of Training and Validation cls Loss between YOLO12 Models')\n",
    "ax.legend(title=' YOLO12 Models (n, m, s)')\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#ax.set_xlim(1, 10)\n",
    "if all_data_found:\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "all_data_found = True\n",
    "for i, path in enumerate(paths):\n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        data.columns = data.columns.str.strip()\n",
    "\n",
    "        # YOLO salva più loss (box, cls, dfl).\n",
    "        # Usiamo 'val/box_loss' e 'train/box_loss' come metriche di confronto.\n",
    "\n",
    "        epoch = data['epoch']\n",
    "        val_loss = data['val/dfl_loss']     # Puoi cambiarla con 'val/cls_loss'\n",
    "        train_loss = data['train/dfl_loss'] # Puoi cambiarla con 'train/cls_loss'\n",
    "\n",
    "        # Validation Loss (Blu)\n",
    "        ax.plot(epoch, val_loss, label=f'Validation Loss {modelli[i]}', color=colors_val[i], linewidth=2, linestyle='-')\n",
    "        # Training Loss (Arancione)\n",
    "        ax.plot(epoch, train_loss, label=f'Training Loss {modelli[i]}', color=colors_train[i], linewidth=2, linestyle='-')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"File non trovato: '{path}'\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "    except KeyError as e:\n",
    "        print(f\"--- ERRORE ---\")\n",
    "        print(f\"Errore nel file: {path}. Colonna non trovata: {e}\")\n",
    "        print(\"-\" * 30)\n",
    "        all_data_found = False\n",
    "\n",
    "ax.set_xlabel('Epoche')\n",
    "ax.set_ylabel('Box Loss (Train & Val)')\n",
    "ax.set_title('Comparison of Training and Validation dfl Loss between YOLO12 Models')\n",
    "ax.legend(title=' YOLO12 Models (n, m, s)')\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "if all_data_found:\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r17WZc6fRuJE"
   },
   "source": [
    "## Comparison of Precision, Recall and F1 metrics between different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5Xnu8AQRsVe",
    "outputId": "a7173fc0-ee8e-41cf-a33a-0b9ae6be572d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics_prf = ['AVG.Precision', 'Avg.Recall', 'Avg.F1']\n",
    "models = ['Yolo12n', 'Yolo12s', 'Yolo12m'] \n",
    "values_prf = np.array([\n",
    "    [np.mean(resultN.box.p), np.mean(resultS.box.p), np.mean(resultM.box.p)],   # values for Precision\n",
    "    [np.mean(resultN.box.r), np.mean(resultS.box.r), np.mean(resultM.box.r)],   # values for Recall\n",
    "    [np.mean(resultN.box.f1), np.mean(resultS.box.f1), np.mean(resultM.box.f1)] # values for F1-score\n",
    "])\n",
    "num_metrics_prf = len(metrics_prf)\n",
    "num_models = len(models)\n",
    "\n",
    "column_width = 0.2\n",
    "gap = 0.1\n",
    "position_bar = np.arange(num_metrics_prf) * (num_models * column_width + gap)\n",
    "\n",
    "colors = ['#F50C00', '#00FF66', '#007BFF']\n",
    "\n",
    "fig_prf, ax_prf = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i in range(num_models):\n",
    "    bars = ax_prf.bar(position_bar + i * column_width, values_prf[:, i], column_width,\n",
    "                      label=models[i], color=colors[i])\n",
    "\n",
    "    ax_prf.bar_label(bars, fmt='%.3f', padding=3, fontsize=9)\n",
    "\n",
    "ax_prf.set_xlabel('metrics')\n",
    "ax_prf.set_ylabel('Value')\n",
    "ax_prf.set_title('Comparison of Precision, Recall and F1 metrics between different models')\n",
    "ax_prf.set_xticks(position_bar + (num_models - 1) * column_width / 2)\n",
    "ax_prf.set_xticklabels(metrics_prf)\n",
    "ax_prf.legend(title='Models', loc='lower right')\n",
    "ax_prf.set_ylim(0, np.max(values_prf) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klRuRxjKRVvZ"
   },
   "source": [
    "## Test for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnR6CPYgRHAY"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from google.colab.patches import cv2_imshow\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def draw_text_with_background(img, text, org, font, font_scale, text_color, bg_color, thickness, padding=5):\n",
    "    (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "\n",
    "    x, y = org\n",
    "    tl = (x - padding, y - text_h - baseline - padding)\n",
    "    br = (x + text_w + padding, y + baseline + padding)\n",
    "\n",
    "    cv2.rectangle(img, tl, br, bg_color, -1)\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness)\n",
    "\n",
    "folder = \"/kaggle/input/street-sign-set/StreetSignSet/test/images\"\n",
    "\n",
    "#model = YOLO(\"/kaggle/input/streetsignsensey12n/pytorch/streetsignsensey12n_350e_final/1/streetsignsense/yolov12n_run/weights/best.pt\")\n",
    "model = YOLO(\"/kaggle/input/streetsignsensey12s/pytorch/streetsignsensey12s_270e_final/1/streetsignsense/yolo12s_run/weights/best.pt\")\n",
    "#model = YOLO(\"/kaggle/input/streetsignsensey12m/pytorch/streetsignsensey12m_245e/1/streetsignsense/yolo12m_run/weights/best.pt\")\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"Nessuna immagine trovata nella cartella: {folder}\")\n",
    "else:\n",
    "    print(f\"Trovate {len(image_files)} immagini.\")\n",
    "\n",
    "for filename in image_files:\n",
    "    image_path = os.path.join(folder, filename)\n",
    "    print(f\"\\nRisultati per: {filename} \")\n",
    "\n",
    "    # ATTENZIONE durante l'inferenza per sfruttare entrambe le GPU T4, si usa l'argomento device='0,1', \n",
    "    # in caso di hardware differente occorre modificare o rimuvere l'agormento.\n",
    "    \n",
    "    # senza salvataggio\n",
    "    results = model(image_path, device='0,1')\n",
    "\n",
    "    # con salvataggio\n",
    "    #results = model.predict(source=image_path, save=True, device='0,1')\n",
    "\n",
    "    # con salvataggio e soglie di IoU e confidenza per scartare predizioni incerte,\n",
    "    #results = model.predict(source=image_path, save=False, iou=0.5, conf=0.5, device='0,1')\n",
    "\n",
    "    # senza salvataggio e soglie di IoU e confidenza per scartare predizioni incerte,\n",
    "    #results = model.predict(source=image_path, save=False, iou=0.5, conf=0.5, device='0,1')\n",
    "\n",
    "    # Immagine Originale\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image_resized = cv2.resize(original_image, (350,350))\n",
    "\n",
    "    # Immagine con Predizioni\n",
    "    prediction_image = results[0].plot() # Questo sostituisce tutto il disegno manuale\n",
    "    prediction_image_resized = cv2.resize(prediction_image, (350,350))\n",
    "\n",
    "    # immagine di Ground Truth\n",
    "    gt_path = os.path.join('//kaggle/usr/lib/sss_groundtruth_annotations/groundTruth/test', filename)\n",
    "    ground_truth_image = cv2.imread(gt_path)\n",
    "\n",
    "    if ground_truth_image is None:\n",
    "        ground_truth_image_resized = cv2.resize(original_image, (350,350))\n",
    "        draw_text_with_background(ground_truth_image_resized, \"GT NOT FOUND\", (50, 175), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), (0, 0, 0), 2)\n",
    "    else:\n",
    "        ground_truth_image_resized = cv2.resize(ground_truth_image, (350,350))\n",
    "\n",
    "    title_font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "    draw_text_with_background(original_image_resized, \"ORIGINAL\", (10, 30), title_font, 1, (255, 255, 255), (0,0,0), 2)\n",
    "    draw_text_with_background(ground_truth_image_resized, \"GROUND TRUTH\", (10, 30), title_font, 1, (255, 255, 255), (20, 180, 20), 2)\n",
    "    draw_text_with_background(prediction_image_resized, \"PREDICTIONS\", (10, 30), title_font, 1, (255, 255, 255), (255, 123, 0), 2)\n",
    "\n",
    "\n",
    "    concat = cv2.hconcat([original_image_resized, ground_truth_image_resized, prediction_image_resized])\n",
    "    cv2_imshow(concat)\n",
    "    print(f\"\\n_____________________________________________________________________________________________________________________________\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OVatb8o6TzaF",
    "r17WZc6fRuJE",
    "klRuRxjKRVvZ"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8410752,
     "sourceId": 13911729,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 282756764,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 519349,
     "modelInstanceId": 504338,
     "sourceId": 666277,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 519354,
     "modelInstanceId": 504344,
     "sourceId": 666283,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 520110,
     "modelInstanceId": 505209,
     "sourceId": 667327,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
